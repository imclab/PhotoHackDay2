<h1 id="visioniqandroidsdk"><strong>VisionIQ Android SDK</strong></h1>

<h1 id="intro">Intro</h1>

<p>IQ Engines provides VisionIQ, an image recognition platform that makes it possible to add visual search to your mobile application. Before diving into the details of how   you can integrate the SDK into your Android application, we give a brief overview of the two engines at the core of VisionIQ: (1) visual search in the cloud, and (2) visual search on the mobile device. You can find more information about VisionIQ on the <a href="http://www.iqengines.com/system/">system overview</a> page.</p>

<h2 id="visioniqserver:visualsearchinthecloud">Vision IQ server : Visual search in the cloud</h2>

<p>When you send an image to the VisionIQ cloud, it is first analyzed by our computer vision algorithms, where we match your image against the IQ Engines&#8217; image dataset as well as your private dataset of images. In the Android SDK search in the cloud is referred to as <em>remote</em> search, as the image processing algorithms are running on VisionIQ&#8217;s remote servers.</p>

<p>When our computer vision algorithms are not able to recognize your image, then it is sent to our crowdsourcing engine, i.e. a person will manually tag your image. By combining computer vision and crowdsourcing, we are able to provide accurate labels for 100% of images.</p>

<h2 id="visioniqmobile:visualsearchonthemobiledevice">Vision IQ mobile : Visual search on the mobile device</h2>

<p>The VisionIQ cloud can scale to recognize millions of images. However, if your dataset is small (~100 objects), then the recognition can happen entirely on the mobile device, with no need for an internet connection as the image isn&#8217;t sent to the VisionIQ cloud. This makes for a really snappy experience, and quasi-instant results. In the Android SDK the search on the mobile device is referred to as <em>local</em> search. If you switch the <em>continuous</em> mode on, then frames are continuously grabbed from the camera and processed in real-time, i.e. there is no need for the user to take an action such as pressing a button to retrieve information about objects within the viewfinder.  </p>

<h2 id="contentsoftheandroidsdk">Contents of the Android SDK</h2>

<ol>
<li>The VisionIQ SDK in the <strong>iqengines-sdk</strong> folder. It contains all the necessary functions to include the VisionIQ functionality in your app.</li>
<li>The VisionIQ demo application in the <strong>iqengines-demo</strong> folder. It shows you an example of how the SDK can be used in a mobile app, along with best practices and a UI that follows Android guidelines.</li>
<li>A set of prebuilt libraries for <a href="http://opencv.willowgarage.com/">OpenCV</a> that are used for the <em>local</em> search. </li>
</ol>

<p>This tutorial focuses on eclipse IDE. If you aren&#8217;t developing on eclipse, please adapt the following instruction to your own IDE.</p>

<h1 id="setupourdemoapp.">Set up our demo app. </h1>

<p>Trying the demo app is the best way to understand both the SDK and VisionIQ&#8217;s capabilities.</p>

<h2 id="installation">Installation</h2>

<ul>
<li>Install the Android <a href="http://developer.android.com/sdk/ndk/index.html">NDK</a></li>
<li>Set the <strong><code>ANDROID_NDK_ROOT</code></strong> variable to the directory where you have installed the NDK in Eclipse->Preferences->Run/Debug->String substitution. This step should be done any time you change your workspace.</li>
</ul>

<p><img id="center" src="http://img.skitch.com/20120511-f132g6p21ycs24mihdcyxy81dy.medium.jpg" alt="center" title="" /></p>

<ul>
<li>Import an <strong>existing project</strong> into your workspace and select the <strong>android-sdk</strong> folder.</li>
</ul>

<p><img id="center" src="http://img.skitch.com/20120511-jraspaepie4brmidwak6tt7g8d.medium.jpg" alt="center" title="" /></p>

<ul>
<li>For each project, in the package explorer right-click your android project and select <strong>Properties</strong>.</li>
<li>In the <strong>Properties</strong> window, select the <strong>Android</strong> properties group at left and locate the <strong>Project Build Target</strong> window on the right.</li>
<li>Pick the chosen version. The SDK works for any API level 8 and above. In order to follow Android&#8217;s guidelines, the Demo-app works for any API level 11 and above.</li>
</ul>

<p><img id="center" src="http://img.skitch.com/20120511-d62rsbax337bekajgtpenmiefn.png" alt="center" title="" /></p>

<ul>
<li>When the dialog closes, click Apply in the <strong>Properties</strong> window.</li>
<li>Click OK to close the <strong>Properties</strong> window.</li>
<li><strong>Clean</strong> your project.</li>
</ul>

<h2 id="configurethevisioniqsdk">Configure the VisionIQ SDK</h2>

<p>When you import the VisionIQ SDK in an app, you can configure it by setting the following variables:</p>

<ul>
<li><strong>KEY</strong>, <strong>SECRET</strong>: your API key and secret obtained after you&#8217;ve signed up for VisionIQ. You can find both keys in the <a href="http://www.iqengines.com/dashboard/queries/">developer center</a> </li>
</ul>

<p><img id="center" src="http://img.skitch.com/20120515-c7418drprn2papjpm3w9t4iq5s.png" alt="center" title="" /></p>

<ul>
<li><em>remote</em> search
<ul>
<li><strong><code>SEARCH_OBJECT_REMOTE</code></strong>: if set to <strong>true</strong>, <em>remote</em> search is enabled. </li>
</ul></li>
<li><em>local</em> search
<ul>
<li><strong><code>SEARCH_OBJECT_LOCAL</code></strong>: if set to <strong>true</strong>, <em>local</em> search is enabled.</li>
<li><strong><code>SEARCH_OBJECT_LOCAL_CONTINUOUS</code></strong>: if set to <strong>true</strong>, <em>local continuous</em> search is enabled.</li>
</ul></li>
</ul>

<p><img id="center" src="http://img.skitch.com/20120511-cbce7rbdtkgkfssi8taqagnssp.png" alt="center" title="" /></p>

<ul>
<li><strong><code>MAX_TEST_LOCAL_SEARCH_TIME</code></strong>: the maximum duration of a <em>local</em> search. If <em>local</em> search is enabled, the VisionIQ SDK runs a test search to assess the processing speed of the mobile device. To provide a consistent experience across the Android ecosystem, <em>local</em> search is disabled for older mobile devices that do not pass the test. In the DemoApp, the test is run in the <strong>onCreate</strong> function in <a href="https://github.com/iqengines/android-sdk/blob/master/iqengines-demo/src/com/iqengines/demo/DemoActivity.java"><strong>DemoActivity.java</strong></a>.</li>
</ul>

<p><img id="center" src="http://img.skitch.com/20120511-ts2y73fkbinnnprf92kdan454p.png" alt="center" title="" /></p>

<blockquote>
  <p>You will find more information about those variables in the next paragraph.</p>
</blockquote>

<p>You are now ready to try the demo-app. launch the application on your own Android device and try VisionIQ. The next paragraph explains how to get a better experience with VisionIQ.</p>

<h1 id="howtousethesdk">How to use the SDK</h1>

<h2 id="manageyourdatasets">Manage your datasets</h2>

<p>You will be dealing with 3 datasets.</p>

<ul>
<li>Your private dataset on the VisionIQ cloud.</li>
<li>The local dataset which is on the device. </li>
<li>IQ Engines&#8217; dataset.</li>
</ul>

<h3 id="theprivatedataset">The private dataset</h3>

<p>The easiest way to manage your own dataset is to use the web site interface. Create your dataset by using the <a href="http://www.iqengines.com/dashboard/upload/">training interface</a>. 
With this interface uploading your data is fast and effortless. </p>

<p>Your data are objects. There are three steps to build a new object.</p>

<ul>
<li>Drag your images in the window.</li>
<li>Set a Name / Label to the set of picture you&#8217;ve just dragged.</li>
<li>Set Meta data to the set of picture (in the example an URL).</li>
</ul>

<p><img id="center" src="http://img.skitch.com/20120515-x9urp6ubcq5e6dqprerscdptk7.png" alt="center" title="" /></p>

<blockquote>
  <p>the more pictures you have of a same object, the more likely it will be recognized.</p>
</blockquote>

<h3 id="thelocaldataset">The local dataset</h3>

<p>The local dataset is a smaller (~100 pictures) dataset available directly on your phone. the recognition algorithm is performed directly on your phone for very fast results. Contrary to the private one, the local dataset can&#8217;t be trained on the web site. To get your own local dataset please contact support@iqengines.com. You will process your pictures and send them back to you. Once you received your data back, put the &#8220;iqedata&#8221; folder in an &#8220;assets&#8221; folder just like the example bellow.</p>

<p><img id="center" src="http://img.skitch.com/20120515-c27n4hfgksdwrehwdrf1ufit97.png" alt="center" title="" /></p>

<h3 id="iqenginesdatasetandcrowdsourcing">IQ Engines dataset and crowdsourcing</h3>

<p>VisionIQ Also allows you to search in the IQ Engines&#8217; data base and to use the crowdsourcing resources in case of unsuccessful search. Pictures tagged by human can also &#8220;train&#8221; the IQ Engines&#8217; dataset : the picture and the tag are stored in the server. This passive way to train the dataset is laborless and more exhaustive since your users will complete the missing data.</p>

<h2 id="managecrowdsourcingtrainingandcomputervisionoptions.">Manage crowdsourcing, training and computer vision options.</h2>

<p>All apps don&#8217;t require crowdsourcing or on device search. VisionIQ allows you to choose not only among <em>remote</em>, <em>local</em>, <em>local continuous</em> search or any combination of the three but also in which dataset you want to perform it. This flexibility is available through the <a href="http://www.iqengines.com/dashboard/settings/">settings</a> on the developer interface.</p>

<p><img id="center" src="http://img.skitch.com/20120515-c5cyp7thaabm7mkp5u57ud6t48.png" alt="center" title="" /></p>

<p>For example, an app performing only remote search in the private dataset would have :</p>

<ul>
<li>In the SDK settings :
<ul>
<li><strong><code>SEARCH_OBJECT_REMOTE</code></strong>=true; </li>
<li><strong><code>SEARCH_OBJECT_LOCAL</code></strong>= false;</li>
<li><strong><code>SEARCH_OBJECT_LOCAL_CONTINUOUS</code></strong>=false;</li>
</ul></li>
<li>In the dashboard settings
<img id="center" src="http://img.skitch.com/20120515-dunphgqy2mfrcqqud7kxs4ibis.png" alt="center" title="" /></li>
</ul>

<h2 id="useallvisioniqspotential">Use all VisionIQ&#8217;s potential </h2>

<p>The <em>local</em> search and the <em>local continuous</em> search are powerful tools that make image recognition very fast in your app. Time for processing an image locally is &lt; 300 milliseconds. Thus, the decisive factor is how you will manage camera and picture formats. Here are some tips and notions to build the better app possible.</p>

<ul>
<li>Both local and remote search deal with every <a href="http://developer.android.com/reference/android/graphics/ImageFormat.html">image format</a>.</li>
<li>The SDK crops the center of the picture and processes it, you should add a target zone to your preview.</li>
<li>There is always a balance between accuracy and speed. Trials are the best way to find the best settings.
<ul>
<li>Compression and conversion are time-consuming operations, avoid them whenever it&#8217;s possible.</li>
<li>Data compressing increases transfer speed and therefore the remote research speed.</li>
<li>Remember that compression involves (in some cases) data loss and lower picture&#8217;s quality.</li>
<li>See the <a href="http://developer.android.com/reference/android/graphics/YuvImage.html">YuvImage</a> and try to manage <a href="http://developer.android.com/reference/android/graphics/ImageFormat.html">YUV format</a> which is the standard output format of Android cameras.</li>
</ul></li>
</ul>

<h1 id="setupthesdkinyourownproject">Set up the SDK in your own project </h1>

<p>To start using IQEngines SDK in your Android project, follow these steps:</p>

<ul>
<li>If the NDK isn&#8217;t set up, install the Android <a href="http://developer.android.com/sdk/ndk/index.html">NDK</a> Set the android <strong><code>ANDROID_SDK_ROOT</code></strong> as explained earlier.</li>
<li>Import both the <strong>OpenCV</strong> project inside prebuilt and the <strong>iqengines-sdk</strong> project into your workspace.</li>
<li>Do the steps <strong>4,5,6</strong> of the iqengines-demo installation explained above. </li>
<li>In the Package Explorer, right-click your <strong>Android project</strong> and select <strong>Properties</strong>.</li>
<li>In the <strong>Properties</strong> window, select the <strong>Android</strong> properties group at left and locate the <strong>Library</strong> window on the right.</li>
<li>Click Add to open the Project Selection dialog.</li>
</ul>

<p><img id="center" src="http://img.skitch.com/20120511-dwc7rj7rjy6ajjjpntbayyrghi.png" alt="center" title="" /></p>

<ul>
<li>From the list of available library projects, select the <strong>iqengines-sdk</strong> project and click OK.</li>
<li>When the dialog closes, click Apply in the <strong>Properties</strong> window.</li>
<li>Click OK to close the <strong>Properties</strong> window.</li>
<li><strong>Clean</strong> your project.</li>
</ul>

<p>You can now use the VisionIQ features on your app.</p>

<h1 id="questions">Questions</h1>

<ul>
<li><a href="http://support.iqengines.com/knowledgebase">FAQ</a></li>
<li>ask your questions at support@iqengines.com</li>
</ul>
